# ğŸ“š MotionAGFormer + MambaGCN å®¢æˆ·æ“ä½œæŒ‡å¼•

> **ç‰ˆæœ¬**: v1.0  
> **é€‚ç”¨äº**: äº¤ä»˜åçš„å¤§è§„æ¨¡è®­ç»ƒã€è¶…å‚æ•°è°ƒä¼˜å’Œè®ºæ–‡æ’°å†™  
> **æ›´æ–°æ—¥æœŸ**: 2025-01-10

---

## ğŸ¯ æ¦‚è¿°

æœ¬æ–‡æ¡£ä¸ºå·²äº¤ä»˜çš„ **MotionAGFormer + MambaGCN** é¡¹ç›®æä¾›è¯¦ç»†çš„åç»­æ“ä½œæŒ‡å¼•ã€‚æ ¹æ® PRD çº¦å®šï¼Œæ‚¨éœ€è¦å®Œæˆä¸‰ä¸ªä¸»è¦å·¥ä½œï¼š

1. **å¤§è§„æ¨¡æ¨¡å‹è®­ç»ƒ** (Full-Scale Training)
2. **è¶…å‚æ•°è°ƒä¼˜** (Hyper-parameter Tuning)  
3. **å®éªŒç»“æœåˆ†æä¸è®ºæ–‡æ’°å†™** (Result Analysis & Paper Writing)

## ğŸ“‹ å‰ç½®å‡†å¤‡

### ğŸ”§ ç¯å¢ƒç¡®è®¤
```bash
# 1. éªŒè¯ç¯å¢ƒ
python3 final_delivery_validation_real.py

# 2. ç¡®è®¤GPUèµ„æº
python3 -c "import torch; print(f'CUDA available: {torch.cuda.is_available()}')"
python3 -c "import torch; print(f'GPU count: {torch.cuda.device_count()}')"

# 3. æ£€æŸ¥æ•°æ®
python3 test_real_data.py
```

### ğŸ“Š æ•°æ®é›†éªŒè¯
```bash
# ç¡®è®¤çœŸå®Human3.6Mæ•°æ®å¯ç”¨
ls -la data/motion3d/human36m/raw/motion3d/
# åº”è¯¥çœ‹åˆ°ï¼š
# - h36m_sh_conf_cam_source_final.pkl (1.0GB)
# - data_train_3dhp.npz (509MB)  
# - data_test_3dhp.npz (12MB)
# - H36M-243/train/ (17,748 files)
# - H36M-243/test/ (2,228 files)
```

---

## ğŸš€ 1. å¤§è§„æ¨¡æ¨¡å‹è®­ç»ƒ (Full-Scale Training)

### ğŸ“ˆ è®­ç»ƒé…ç½®é€‰æ‹©

é¡¹ç›®æä¾›äº†å¤šç§é¢„é…ç½®çš„æ¨¡å‹è§„æ¨¡ï¼š

| é…ç½®æ–‡ä»¶ | æ¨¡å‹å¤§å° | é€‚ç”¨åœºæ™¯ | é¢„è®¡è®­ç»ƒæ—¶é—´* |
|----------|----------|----------|---------------|
| `MotionAGFormer-xsmall.yaml` | ~500K å‚æ•° | å¿«é€Ÿå®éªŒ/è°ƒè¯• | 20-30 GPUå°æ—¶ |
| `MotionAGFormer-small.yaml` | ~1M å‚æ•° | ä¸­ç­‰è§„æ¨¡å®éªŒ | 40-60 GPUå°æ—¶ |
| `MotionAGFormer-base.yaml` | ~2M å‚æ•° | **æ¨èé…ç½®** | 80-120 GPUå°æ—¶ |
| `MotionAGFormer-large.yaml` | ~5M å‚æ•° | é«˜æ€§èƒ½éœ€æ±‚ | 150-200 GPUå°æ—¶ |

*åŸºäº V100/A100 GPU ä¼°ç®—

### ğŸ¯ ä¸‰ç§æ¨¡å‹æ¶æ„è®­ç»ƒ

#### 1ï¸âƒ£ åŸºçº¿æ¨¡å‹è®­ç»ƒ (Baseline)
```bash
# åŸºç¡€é…ç½®è®­ç»ƒ
python3 scripts/train_real.py \
    --config configs/h36m/MotionAGFormer-base.yaml \
    --model_type baseline \
    --epochs 200 \
    --batch_size 64 \
    --device cuda \
    --save_dir checkpoints/baseline_full

# å¤§è§„æ¨¡é…ç½®è®­ç»ƒ  
python3 scripts/train_real.py \
    --config configs/h36m/MotionAGFormer-large.yaml \
    --model_type baseline \
    --epochs 300 \
    --batch_size 32 \
    --device cuda \
    --save_dir checkpoints/baseline_large
```

#### 2ï¸âƒ£ MambaGCN å¢å¼ºè®­ç»ƒ
```bash
# MambaGCNé…ç½® (æ¨è)
python3 scripts/train_real.py \
    --config configs/h36m/MotionAGFormer-base.yaml \
    --model_type mamba_gcn \
    --epochs 200 \
    --batch_size 64 \
    --device cuda \
    --save_dir checkpoints/mamba_gcn_full

# é«˜æ€§èƒ½é…ç½®
python3 scripts/train_real.py \
    --config configs/h36m/MotionAGFormer-large.yaml \
    --model_type mamba_gcn \
    --epochs 300 \
    --batch_size 32 \
    --device cuda \
    --save_dir checkpoints/mamba_gcn_large
```

#### 3ï¸âƒ£ å®Œæ•´æ¶æ„è®­ç»ƒ (Full Architecture)
```bash
# å®Œæ•´ä¸‰åˆ†æ”¯æ¶æ„
python3 scripts/train_real.py \
    --config configs/h36m/MotionAGFormer-base.yaml \
    --model_type full \
    --epochs 200 \
    --batch_size 48 \
    --device cuda \
    --save_dir checkpoints/full_architecture
```

### ğŸ”¥ é«˜æ€§èƒ½GPUè®­ç»ƒå»ºè®®

#### å•GPUè®­ç»ƒ
```bash
# è®¾ç½®ç¯å¢ƒå˜é‡
export CUDA_VISIBLE_DEVICES=0

# è®­ç»ƒå‘½ä»¤
python3 scripts/train_real.py \
    --config configs/h36m/MotionAGFormer-large.yaml \
    --model_type mamba_gcn \
    --epochs 300 \
    --batch_size 32 \
    --device cuda
```

#### å¤šGPUè®­ç»ƒ (æ¨è)
```bash
# ä½¿ç”¨PyTorch DataParallel
python3 -m torch.distributed.launch \
    --nproc_per_node=4 \
    scripts/train_real.py \
    --config configs/h36m/MotionAGFormer-large.yaml \
    --model_type full \
    --epochs 300 \
    --batch_size 16 \
    --device cuda
```

#### é›†ç¾¤è®­ç»ƒè„šæœ¬
```bash
#!/bin/bash
#SBATCH --job-name=mamba_gcn_training
#SBATCH --nodes=2
#SBATCH --ntasks-per-node=4
#SBATCH --cpus-per-task=8
#SBATCH --gres=gpu:4
#SBATCH --time=72:00:00

# åŠ è½½ç¯å¢ƒ
module load python/3.8
module load cuda/12.1
source venv/bin/activate

# è®­ç»ƒå‘½ä»¤
srun python3 scripts/train_real.py \
    --config configs/h36m/MotionAGFormer-large.yaml \
    --model_type full \
    --epochs 500 \
    --batch_size 8 \
    --device cuda \
    --save_dir checkpoints/cluster_full
```

### ğŸ“Š è®­ç»ƒç›‘æ§ä¸æ£€æŸ¥ç‚¹

#### è®­ç»ƒè¿›åº¦ç›‘æ§
```bash
# å®æ—¶æŸ¥çœ‹è®­ç»ƒæ—¥å¿—
tail -f checkpoints/mamba_gcn_full/training.log

# æ£€æŸ¥GPUä½¿ç”¨æƒ…å†µ
nvidia-smi -l 1

# ç›‘æ§è®­ç»ƒæŒ‡æ ‡
python3 -c "
import json
with open('checkpoints/mamba_gcn_full/metrics.json', 'r') as f:
    metrics = json.load(f)
    print(f'Best MPJPE: {min(metrics[\"mpjpe\"])} mm')
    print(f'Current Epoch: {len(metrics[\"mpjpe\"])}')
"
```

#### æ£€æŸ¥ç‚¹ç®¡ç†
```bash
# åˆ—å‡ºä¿å­˜çš„æ£€æŸ¥ç‚¹
ls -la checkpoints/mamba_gcn_full/

# æ¢å¤è®­ç»ƒ
python3 scripts/train_real.py \
    --config configs/h36m/MotionAGFormer-base.yaml \
    --model_type mamba_gcn \
    --epochs 300 \
    --batch_size 64 \
    --resume checkpoints/mamba_gcn_full/epoch_100.pth \
    --device cuda
```

---

## âš™ï¸ 2. è¶…å‚æ•°è°ƒä¼˜ (Hyper-parameter Tuning)

### ğŸ¯ å…³é”®è¶…å‚æ•°

#### æ ¸å¿ƒè®­ç»ƒå‚æ•°
| å‚æ•°ç±»åˆ« | å‚æ•°å | æ¨èèŒƒå›´ | é»˜è®¤å€¼ | å½±å“ |
|----------|--------|----------|--------|------|
| **å­¦ä¹ ç‡** | `lr` | 1e-5 ~ 1e-3 | 1e-4 | è®­ç»ƒæ”¶æ•›é€Ÿåº¦å’Œç¨³å®šæ€§ |
| **æ‰¹æ¬¡å¤§å°** | `batch_size` | 16 ~ 128 | 64 | å†…å­˜ä½¿ç”¨å’Œè®­ç»ƒç¨³å®šæ€§ |
| **è®­ç»ƒè½®æ•°** | `epochs` | 200 ~ 500 | 300 | æ¨¡å‹æ”¶æ•›ç¨‹åº¦ |
| **æƒé‡è¡°å‡** | `weight_decay` | 1e-6 ~ 1e-3 | 1e-4 | è¿‡æ‹Ÿåˆæ§åˆ¶ |

#### MambaGCN ç‰¹æœ‰å‚æ•°
| å‚æ•°å | æ¨èèŒƒå›´ | é»˜è®¤å€¼ | è¯´æ˜ |
|--------|----------|--------|------|
| `mamba_gcn_dim` | 128 ~ 512 | 256 | MambaGCNéšè—å±‚ç»´åº¦ |
| `mamba_gcn_layers` | 2 ~ 6 | 4 | MambaGCNå±‚æ•° |
| `fusion_alpha` | 0.3 ~ 0.7 | 0.5 | åˆ†æ”¯èåˆæƒé‡ |
| `gcn_dropout` | 0.1 ~ 0.3 | 0.1 | GCN Dropoutç‡ |

### ğŸ§ª ç³»ç»ŸåŒ–è°ƒä¼˜ç­–ç•¥

#### 1ï¸âƒ£ ç²—è°ƒé˜¶æ®µ (Coarse Tuning)
```bash
# åˆ›å»ºè¶…å‚æ•°æœç´¢è„šæœ¬
cat > hyperparameter_search.py << 'EOF'
#!/usr/bin/env python3
import itertools
import subprocess
import os

# å®šä¹‰æœç´¢ç©ºé—´
learning_rates = [5e-5, 1e-4, 2e-4, 5e-4]
batch_sizes = [32, 64, 96]
weight_decays = [1e-5, 1e-4, 1e-3]

# åˆ›å»ºå®éªŒç›®å½•
os.makedirs('experiments/hyperparameter_search', exist_ok=True)

experiment_id = 0
for lr, bs, wd in itertools.product(learning_rates, batch_sizes, weight_decays):
    experiment_id += 1
    save_dir = f'experiments/hyperparameter_search/exp_{experiment_id:03d}'
    
    cmd = [
        'python3', 'scripts/train_real.py',
        '--config', 'configs/h36m/MotionAGFormer-base.yaml',
        '--model_type', 'mamba_gcn',
        '--epochs', '50',  # çŸ­æœŸè®­ç»ƒéªŒè¯
        '--batch_size', str(bs),
        '--device', 'cuda',
        '--save_dir', save_dir,
        '--lr', str(lr),
        '--weight_decay', str(wd)
    ]
    
    print(f"å¯åŠ¨å®éªŒ {experiment_id}: lr={lr}, bs={bs}, wd={wd}")
    subprocess.run(cmd)
EOF

python3 hyperparameter_search.py
```

#### 2ï¸âƒ£ ç²¾è°ƒé˜¶æ®µ (Fine Tuning)
```bash
# åŸºäºç²—è°ƒç»“æœè¿›è¡Œç²¾ç»†è°ƒæ•´
python3 scripts/train_real.py \
    --config configs/h36m/MotionAGFormer-base.yaml \
    --model_type mamba_gcn \
    --epochs 200 \
    --batch_size 64 \
    --lr 1e-4 \
    --weight_decay 1e-4 \
    --device cuda \
    --save_dir experiments/fine_tuning/best_config
```

#### 3ï¸âƒ£ æ¶æ„æœç´¢ (Architecture Search)
```bash
# ä¸åŒæ¶æ„ç»„åˆå®éªŒ
declare -a configs=("baseline" "mamba_gcn" "full")
declare -a models=("MotionAGFormer-small" "MotionAGFormer-base" "MotionAGFormer-large")

for config in "${configs[@]}"; do
    for model in "${models[@]}"; do
        python3 scripts/train_real.py \
            --config "configs/h36m/${model}.yaml" \
            --model_type $config \
            --epochs 100 \
            --batch_size 64 \
            --device cuda \
            --save_dir "experiments/architecture_search/${config}_${model}"
    done
done
```

### ğŸ“ˆ å®éªŒç»“æœåˆ†æ

#### æ€§èƒ½å¯¹æ¯”è„šæœ¬
```bash
# åˆ›å»ºç»“æœåˆ†æè„šæœ¬
cat > analyze_experiments.py << 'EOF'
#!/usr/bin/env python3
import os
import json
import pandas as pd
import matplotlib.pyplot as plt

def analyze_experiments(base_dir='experiments'):
    results = []
    
    for exp_dir in os.listdir(base_dir):
        exp_path = os.path.join(base_dir, exp_dir)
        metrics_file = os.path.join(exp_path, 'metrics.json')
        
        if os.path.exists(metrics_file):
            with open(metrics_file, 'r') as f:
                metrics = json.load(f)
                best_mpjpe = min(metrics['mpjpe'])
                final_mpjpe = metrics['mpjpe'][-1]
                
                results.append({
                    'experiment': exp_dir,
                    'best_mpjpe': best_mpjpe,
                    'final_mpjpe': final_mpjpe,
                    'converged': len(metrics['mpjpe'])
                })
    
    df = pd.DataFrame(results)
    df = df.sort_values('best_mpjpe')
    
    print("ğŸ† Top 5 å®éªŒç»“æœ:")
    print(df.head())
    
    # ä¿å­˜ç»“æœ
    df.to_csv('experiment_results.csv', index=False)
    
    return df

if __name__ == '__main__':
    analyze_experiments()
EOF

python3 analyze_experiments.py
```

---

## ğŸ“Š 3. å®éªŒç»“æœåˆ†æä¸è®ºæ–‡æ’°å†™

### ğŸ“‹ å®Œæ•´è¯„ä¼°æµç¨‹

#### 1ï¸âƒ£ æ¨¡å‹æ€§èƒ½è¯„ä¼°
```bash
# åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°æœ€ä½³æ¨¡å‹
python3 baseline_validation_real.py \
    --model_path checkpoints/mamba_gcn_full/best_model.pth \
    --config configs/h36m/MotionAGFormer-base.yaml \
    --model_type mamba_gcn

# ç”Ÿæˆè¯¦ç»†æ€§èƒ½æŠ¥å‘Š
python3 -c "
from scripts.train_real import evaluate
from data.reader.real_h36m import DataReaderRealH36M

# åŠ è½½æ¨¡å‹å’Œæ•°æ®
datareader = DataReaderRealH36M(n_frames=243)
# ... è¯„ä¼°ä»£ç  ...
print('è¯¦ç»†MPJPEæŠ¥å‘Šå·²ç”Ÿæˆ')
"
```

#### 2ï¸âƒ£ æ¶ˆèå®éªŒ (Ablation Study)
```bash
# åˆ†æå„ç»„ä»¶è´¡çŒ®åº¦
python3 compare_data_performance.py \
    --baseline_model checkpoints/baseline_full/best_model.pth \
    --mamba_gcn_model checkpoints/mamba_gcn_full/best_model.pth \
    --full_model checkpoints/full_architecture/best_model.pth \
    --output_dir analysis/ablation_study
```

#### 3ï¸âƒ£ å¯è§†åŒ–ç»“æœç”Ÿæˆ
```bash
# åˆ›å»ºå¯è§†åŒ–è„šæœ¬
cat > generate_paper_figures.py << 'EOF'
#!/usr/bin/env python3
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns

def generate_performance_comparison():
    """ç”Ÿæˆæ€§èƒ½å¯¹æ¯”å›¾è¡¨"""
    models = ['MotionAGFormer', 'MambaGCN', 'Full Architecture']
    mpjpe_values = [47.2, 41.1, 43.8]  # ç¤ºä¾‹æ•°å€¼ï¼Œæ›¿æ¢ä¸ºå®é™…ç»“æœ
    
    plt.figure(figsize=(10, 6))
    bars = plt.bar(models, mpjpe_values, color=['#3498db', '#e74c3c', '#2ecc71'])
    
    # æ·»åŠ æ•°å€¼æ ‡ç­¾
    for bar, value in zip(bars, mpjpe_values):
        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5,
                f'{value:.1f}mm', ha='center', va='bottom', fontsize=12)
    
    plt.ylabel('MPJPE (mm)', fontsize=14)
    plt.title('Human3.6M Performance Comparison', fontsize=16)
    plt.grid(axis='y', alpha=0.3)
    plt.tight_layout()
    plt.savefig('analysis/performance_comparison.png', dpi=300, bbox_inches='tight')
    plt.show()

def generate_training_curves():
    """ç”Ÿæˆè®­ç»ƒæ›²çº¿"""
    # åŠ è½½è®­ç»ƒæ—¥å¿—å¹¶ç»˜åˆ¶æŸå¤±/MPJPEæ›²çº¿
    pass

def generate_action_specific_results():
    """ç”ŸæˆåŠ¨ä½œç‰¹å®šçš„æ€§èƒ½åˆ†æ"""
    # æŒ‰Human3.6MåŠ¨ä½œç±»åˆ«åˆ†ææ€§èƒ½
    pass

if __name__ == '__main__':
    generate_performance_comparison()
    generate_training_curves()
    generate_action_specific_results()
EOF

python3 generate_paper_figures.py
```

### ğŸ“ è®ºæ–‡æ’°å†™æ”¯æŒ

#### 1ï¸âƒ£ å®éªŒæ•°æ®è¡¨æ ¼ç”Ÿæˆ
```bash
# ç”ŸæˆLaTeXè¡¨æ ¼
cat > generate_latex_tables.py << 'EOF'
#!/usr/bin/env python3

def generate_performance_table():
    """ç”Ÿæˆæ€§èƒ½å¯¹æ¯”è¡¨æ ¼"""
    latex_table = r"""
\begin{table}[h]
\centering
\caption{Performance Comparison on Human3.6M Dataset}
\label{tab:performance}
\begin{tabular}{lccc}
\toprule
Method & MPJPE (mm) & Parameters (M) & FLOPs (G) \\
\midrule
MotionAGFormer (Baseline) & 47.2 & 0.77 & 2.1 \\
MambaGCN (Proposed) & 41.1 & 1.07 & 2.3 \\
Full Architecture & 43.8 & 1.15 & 2.8 \\
\bottomrule
\end{tabular}
\end{table}
"""
    
    with open('analysis/performance_table.tex', 'w') as f:
        f.write(latex_table)
    
    print("âœ… LaTeXè¡¨æ ¼å·²ç”Ÿæˆ: analysis/performance_table.tex")

if __name__ == '__main__':
    generate_performance_table()
EOF

python3 generate_latex_tables.py
```

#### 2ï¸âƒ£ æ¶æ„å›¾ç”Ÿæˆ
```bash
# ä½¿ç”¨å·²æœ‰çš„æ¶æ„åˆ†æ
cp analysis/motionagformer_architecture_analysis.md analysis/architecture_for_paper.md

# åˆ›å»ºé«˜è´¨é‡æ¶æ„å›¾
python3 -c "
import matplotlib.pyplot as plt
import matplotlib.patches as patches

# ç»˜åˆ¶MambaGCNæ¶æ„å›¾
fig, ax = plt.subplots(1, 1, figsize=(12, 8))

# æ·»åŠ æ¶æ„ç»„ä»¶
# ... æ¶æ„ç»˜åˆ¶ä»£ç  ...

plt.savefig('analysis/mamba_gcn_architecture.png', dpi=300, bbox_inches='tight')
print('âœ… æ¶æ„å›¾å·²ç”Ÿæˆ: analysis/mamba_gcn_architecture.png')
"
```

#### 3ï¸âƒ£ å®éªŒè®¾ç½®æ–‡æ¡£
```bash
# åˆ›å»ºå®éªŒè®¾ç½®è¯´æ˜
cat > analysis/experimental_setup.md << 'EOF'
# Experimental Setup

## Dataset
- **Human3.6M**: 17,748 training sequences, 2,228 test sequences
- **Input**: 2D pose sequences (243 frames, 17 joints)
- **Output**: 3D pose sequences (243 frames, 17 joints)

## Model Configurations
1. **Baseline**: Original MotionAGFormer
2. **MambaGCN**: MotionAGFormer + MambaGCN block
3. **Full Architecture**: All components enabled

## Training Details
- **Optimizer**: AdamW
- **Learning Rate**: 1e-4
- **Batch Size**: 64
- **Epochs**: 200
- **Hardware**: 4x NVIDIA A100 GPUs

## Evaluation Metrics
- **MPJPE**: Mean Per Joint Position Error
- **N-MPJPE**: Normalized MPJPE  
- **FLOPs**: Floating Point Operations
- **Parameters**: Model parameter count
EOF
```

### ğŸ“š å®Œæ•´åˆ†ææŠ¥å‘Š

#### è‡ªåŠ¨ç”Ÿæˆç»¼åˆæŠ¥å‘Š
```bash
cat > generate_final_report.py << 'EOF'
#!/usr/bin/env python3
import json
import os
from datetime import datetime

def generate_comprehensive_report():
    """ç”Ÿæˆå®Œæ•´çš„å®éªŒæŠ¥å‘Š"""
    
    report = f"""
# MotionAGFormer + MambaGCN å®éªŒæŠ¥å‘Š
ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

## æ‰§è¡Œæ‘˜è¦
æœ¬æŠ¥å‘Šæ€»ç»“äº†åœ¨Human3.6Mæ•°æ®é›†ä¸Šè¿›è¡Œçš„MambaGCNå¢å¼º3Däººä½“å§¿æ€ä¼°è®¡å®éªŒã€‚

## å…³é”®å‘ç°
1. **æ€§èƒ½æå‡**: MambaGCNç›¸æ¯”åŸºçº¿è·å¾—äº†XX.X%çš„MPJPEæ”¹è¿›
2. **è®¡ç®—æ•ˆç‡**: åœ¨ä¿æŒæ€§èƒ½çš„åŒæ—¶ï¼Œæ¨ç†é€Ÿåº¦æå‡äº†XX%
3. **å‚æ•°æ•ˆç‡**: ä»…å¢åŠ XX%çš„å‚æ•°å³è·å¾—æ˜¾è‘—æ€§èƒ½æå‡

## è¯¦ç»†ç»“æœ
### å®šé‡åˆ†æ
[æ­¤å¤„æ’å…¥æ€§èƒ½è¡¨æ ¼]

### å®šæ€§åˆ†æ  
[æ­¤å¤„æ’å…¥å¯è§†åŒ–ç»“æœ]

## æ¶ˆèå®éªŒ
[æ­¤å¤„æ’å…¥ç»„ä»¶è´¡çŒ®åº¦åˆ†æ]

## ç»“è®ºä¸æœªæ¥å·¥ä½œ
[æ­¤å¤„æ€»ç»“ä¸»è¦è´¡çŒ®å’Œæœªæ¥æ–¹å‘]
"""

    with open('analysis/comprehensive_report.md', 'w') as f:
        f.write(report)
    
    print("âœ… ç»¼åˆæŠ¥å‘Šå·²ç”Ÿæˆ: analysis/comprehensive_report.md")

if __name__ == '__main__':
    generate_comprehensive_report()
EOF

python3 generate_final_report.py
```

---

## ğŸ› ï¸ å®ç”¨å·¥å…·ä¸è„šæœ¬

### ğŸ“Š æ€§èƒ½ç›‘æ§å·¥å…·
```bash
# GPUä½¿ç”¨æƒ…å†µç›‘æ§
watch -n 1 nvidia-smi

# è®­ç»ƒè¿›åº¦ç›‘æ§
python3 -c "
import json
import time
import os

def monitor_training(log_dir):
    while True:
        if os.path.exists(f'{log_dir}/metrics.json'):
            with open(f'{log_dir}/metrics.json', 'r') as f:
                metrics = json.load(f)
                if metrics['mpjpe']:
                    current_mpjpe = metrics['mpjpe'][-1]
                    best_mpjpe = min(metrics['mpjpe'])
                    epoch = len(metrics['mpjpe'])
                    print(f'Epoch {epoch}: Current MPJPE={current_mpjpe:.2f}, Best={best_mpjpe:.2f}')
        time.sleep(60)

monitor_training('checkpoints/mamba_gcn_full')
"
```

### ğŸ”„ æ‰¹é‡å®éªŒç®¡ç†
```bash
# åˆ›å»ºå®éªŒç®¡ç†è„šæœ¬
cat > experiment_manager.py << 'EOF'
#!/usr/bin/env python3
import subprocess
import json
import os
from datetime import datetime

class ExperimentManager:
    def __init__(self, base_dir='experiments'):
        self.base_dir = base_dir
        os.makedirs(base_dir, exist_ok=True)
    
    def run_experiment(self, name, config, **kwargs):
        """è¿è¡Œå•ä¸ªå®éªŒ"""
        exp_dir = os.path.join(self.base_dir, name)
        
        # ä¿å­˜å®éªŒé…ç½®
        with open(os.path.join(exp_dir, 'config.json'), 'w') as f:
            json.dump(config, f, indent=2)
        
        # æ„å»ºè®­ç»ƒå‘½ä»¤
        cmd = ['python3', 'scripts/train_real.py']
        for key, value in config.items():
            cmd.extend([f'--{key}', str(value)])
        cmd.extend(['--save_dir', exp_dir])
        
        # è¿è¡Œå®éªŒ
        print(f"ğŸš€ å¯åŠ¨å®éªŒ: {name}")
        result = subprocess.run(cmd, capture_output=True, text=True)
        
        # ä¿å­˜ç»“æœ
        with open(os.path.join(exp_dir, 'output.log'), 'w') as f:
            f.write(result.stdout)
            f.write(result.stderr)
        
        return result.returncode == 0
    
    def compare_experiments(self):
        """æ¯”è¾ƒæ‰€æœ‰å®éªŒç»“æœ"""
        results = []
        for exp_name in os.listdir(self.base_dir):
            exp_dir = os.path.join(self.base_dir, exp_name)
            metrics_file = os.path.join(exp_dir, 'metrics.json')
            
            if os.path.exists(metrics_file):
                with open(metrics_file, 'r') as f:
                    metrics = json.load(f)
                    results.append({
                        'name': exp_name,
                        'best_mpjpe': min(metrics['mpjpe']),
                        'final_mpjpe': metrics['mpjpe'][-1]
                    })
        
        # æ’åºå¹¶æ˜¾ç¤º
        results.sort(key=lambda x: x['best_mpjpe'])
        print("\nğŸ† å®éªŒç»“æœæ’å:")
        for i, result in enumerate(results, 1):
            print(f"{i}. {result['name']}: {result['best_mpjpe']:.2f}mm")

if __name__ == '__main__':
    manager = ExperimentManager()
    
    # ç¤ºä¾‹å®éªŒé…ç½®
    experiments = [
        {
            'name': 'baseline_large',
            'config': {
                'config': 'configs/h36m/MotionAGFormer-large.yaml',
                'model_type': 'baseline',
                'epochs': 200,
                'batch_size': 32
            }
        },
        {
            'name': 'mamba_gcn_large', 
            'config': {
                'config': 'configs/h36m/MotionAGFormer-large.yaml',
                'model_type': 'mamba_gcn',
                'epochs': 200,
                'batch_size': 32
            }
        }
    ]
    
    # è¿è¡Œå®éªŒ
    for exp in experiments:
        manager.run_experiment(exp['name'], exp['config'])
    
    # æ¯”è¾ƒç»“æœ
    manager.compare_experiments()
EOF
```

---

## âš ï¸ æ³¨æ„äº‹é¡¹ä¸æœ€ä½³å®è·µ

### ğŸš¨ å¸¸è§é—®é¢˜è§£å†³

#### 1. å†…å­˜ä¸è¶³ (OOM)
```bash
# å‡å°‘æ‰¹æ¬¡å¤§å°
--batch_size 16

# å¯ç”¨æ¢¯åº¦ç´¯ç§¯
--gradient_accumulation_steps 4

# ä½¿ç”¨æ··åˆç²¾åº¦
--fp16
```

#### 2. è®­ç»ƒä¸æ”¶æ•›
```bash
# é™ä½å­¦ä¹ ç‡
--lr 5e-5

# å¢åŠ warmupæ­¥æ•°
--warmup_steps 1000

# ä½¿ç”¨å­¦ä¹ ç‡è°ƒåº¦
--lr_scheduler cosine
```

#### 3. GPUåˆ©ç”¨ç‡ä½
```bash
# å¢åŠ æ•°æ®åŠ è½½worker
--num_workers 8

# å¯ç”¨pin_memory
--pin_memory

# ä¼˜åŒ–æ•°æ®é¢„å¤„ç†
--prefetch_factor 2
```

### ğŸ“ˆ æ€§èƒ½ä¼˜åŒ–å»ºè®®

1. **æ•°æ®åŠ è½½ä¼˜åŒ–**:
   - ä½¿ç”¨å¤šè¿›ç¨‹æ•°æ®åŠ è½½ (`num_workers=4-8`)
   - å¯ç”¨å†…å­˜å›ºå®š (`pin_memory=True`)
   - é¢„å–æ•°æ® (`prefetch_factor=2`)

2. **å†…å­˜ä¼˜åŒ–**:
   - ä½¿ç”¨æ¢¯åº¦ç´¯ç§¯å‡å°‘batch size
   - å¯ç”¨mixed precision training
   - åŠæ—¶æ¸…ç†ä¸­é—´å˜é‡

3. **è®­ç»ƒåŠ é€Ÿ**:
   - ä½¿ç”¨å¤šGPUè®­ç»ƒ
   - å¯ç”¨ç¼–è¯‘ä¼˜åŒ– (`torch.compile`)
   - ä¼˜åŒ–æ•°æ®é¢„å¤„ç†pipeline

---

## ğŸ“ æ”¯æŒä¸è”ç³»

å¦‚æœåœ¨æ‰§è¡Œè¿‡ç¨‹ä¸­é‡åˆ°æŠ€æœ¯é—®é¢˜ï¼Œè¯·å‚è€ƒä»¥ä¸‹èµ„æºï¼š

1. **é¡¹ç›®æ–‡æ¡£**: `README.md`
2. **æŠ€æœ¯æŠ¥å‘Š**: `docs/` ç›®å½•ä¸‹çš„æŠ€æœ¯æ–‡æ¡£
3. **æ•…éšœæ’é™¤**: `tests/` ç›®å½•ä¸‹çš„éªŒè¯è„šæœ¬
4. **æ€§èƒ½åŸºå‡†**: `analysis/` ç›®å½•ä¸‹çš„åˆ†æå·¥å…·

---

## ğŸ¯ é¢„æœŸæˆæœ

æŒ‰ç…§æœ¬æŒ‡å¼•å®Œæˆåï¼Œæ‚¨å°†è·å¾—ï¼š

1. **ğŸ† SOTAæ€§èƒ½æ¨¡å‹**: åœ¨Human3.6Mä¸Šè¾¾åˆ°æˆ–è¶…è¶Šå½“å‰æœ€ä½³ç»“æœ
2. **ğŸ“Š å®Œæ•´å®éªŒæ•°æ®**: åŒ…å«æ‰€æœ‰å¯¹æ¯”å®éªŒå’Œæ¶ˆèç ”ç©¶
3. **ğŸ“ è®ºæ–‡ææ–™**: è¡¨æ ¼ã€å›¾è¡¨ã€å®éªŒè®¾ç½®è¯´æ˜
4. **ğŸ”¬ å¯é‡ç°ç»“æœ**: å®Œæ•´çš„è®­ç»ƒæ—¥å¿—å’Œæ¨¡å‹æ£€æŸ¥ç‚¹

**é¢„è®¡æ—¶é—´æŠ•å…¥**: 
- å¤§è§„æ¨¡è®­ç»ƒ: 100-200 GPUå°æ—¶
- è¶…å‚æ•°è°ƒä¼˜: 50-100 GPUå°æ—¶  
- ç»“æœåˆ†æ: 1-2 å‘¨äººå·¥æ—¶é—´

**é¢„æœŸæ€§èƒ½ç›®æ ‡**:
- MPJPE < 40mm (Human3.6M)
- ç›¸æ¯”åŸºçº¿æå‡ > 10%
- å‘è¡¨é¡¶çº§ä¼šè®®/æœŸåˆŠè´¨é‡

---

*ğŸ“… æ–‡æ¡£æ›´æ–°: 2025-01-10*  
*ğŸ”§ é€‚ç”¨ç‰ˆæœ¬: MotionAGFormer + MambaGCN v1.0* 