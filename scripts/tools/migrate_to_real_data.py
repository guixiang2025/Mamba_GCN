#!/usr/bin/env python3
"""
Data Migration Script: Mock â†’ Real Human3.6M Data
å¤„ç†Task 2.5ä¸­è¯†åˆ«çš„ç¼ºå£ - ä»æ¨¡æ‹Ÿæ•°æ®è½¬æ¢ä¸ºçœŸå®Human3.6Mæ•°æ®
"""

import os
import sys
import argparse
import shutil
import subprocess
from pathlib import Path


def check_real_data_availability():
    """æ£€æŸ¥çœŸå®Human3.6Mæ•°æ®çš„å¯ç”¨æ€§"""
    print("ğŸ” æ£€æŸ¥çœŸå®Human3.6Mæ•°æ®...")

    data_files = [
        'data/motion3d/human36m/raw/motion3d/h36m_sh_conf_cam_source_final.pkl',
        'data/motion3d/human36m/raw/motion3d/data_train_3dhp.npz',
        'data/motion3d/human36m/raw/motion3d/data_test_3dhp.npz',
        'data/motion3d/human36m/raw/motion3d/H36M-243/train',
        'data/motion3d/human36m/raw/motion3d/H36M-243/test'
    ]

    missing_files = []
    for file_path in data_files:
        if not os.path.exists(file_path):
            missing_files.append(file_path)
            print(f"  âŒ ç¼ºå¤±: {file_path}")
        else:
            print(f"  âœ… å­˜åœ¨: {file_path}")

    if missing_files:
        print(f"\nâš ï¸  å‘ç° {len(missing_files)} ä¸ªç¼ºå¤±æ–‡ä»¶")
        return False
    else:
        print("\nâœ… æ‰€æœ‰çœŸå®æ•°æ®æ–‡ä»¶éƒ½å¯ç”¨")
        return True


def backup_mock_files():
    """å¤‡ä»½å½“å‰çš„mockæ•°æ®å’Œç›¸å…³æ–‡ä»¶"""
    print("\nğŸ’¾ å¤‡ä»½å½“å‰mockæ•°æ®æ–‡ä»¶...")

    backup_dir = "data/backup_mock"
    os.makedirs(backup_dir, exist_ok=True)

    files_to_backup = [
        'data/reader/mock_h36m.py',
        'scripts/train_mock.py',
        'data/motion3d/data_3d_h36m_mock.npz',
        'data/motion3d/data_2d_h36m_cpn_ft_h36m_dbb_mock.npz',
        'data/motion3d/test_data_small.npz'
    ]

    for file_path in files_to_backup:
        if os.path.exists(file_path):
            backup_path = os.path.join(backup_dir, os.path.basename(file_path))
            shutil.copy2(file_path, backup_path)
            print(f"  âœ… å¤‡ä»½: {file_path} â†’ {backup_path}")

    print(f"ğŸ“¦ Mockæ•°æ®å¤‡ä»½å®Œæˆ: {backup_dir}")


def create_real_training_script():
    """åˆ›å»ºä½¿ç”¨çœŸå®æ•°æ®çš„è®­ç»ƒè„šæœ¬"""
    print("\nğŸš‚ åˆ›å»ºçœŸå®æ•°æ®è®­ç»ƒè„šæœ¬...")

    train_real_content = '''#!/usr/bin/env python3
"""
Real H36M Training Script for MotionAGFormer + MambaGCN
Uses actual Human3.6M dataset for authentic training and evaluation
"""

import argparse
import os
import numpy as np
import torch
import torch.nn as nn
from torch import optim
from torch.utils.data import DataLoader, Dataset
from tqdm import tqdm

# Import from project modules
from data.reader.real_h36m import DataReaderRealH36M
from model.MotionAGFormer import MotionAGFormer
from loss.pose3d import loss_mpjpe, n_mpjpe, loss_velocity
from utils.tools import set_random_seed, get_config
from utils.learning import AverageMeter


class RealH36MDataset(Dataset):
    """Dataset wrapper for real H36M data"""
    def __init__(self, data_2d, data_3d):
        self.data_2d = torch.FloatTensor(data_2d)
        self.data_3d = torch.FloatTensor(data_3d)
        
    def __len__(self):
        return len(self.data_2d)
    
    def __getitem__(self, idx):
        return self.data_2d[idx], self.data_3d[idx]


def parse_args():
    parser = argparse.ArgumentParser(description='MotionAGFormer + MambaGCN Real H36M Training')
    parser.add_argument('--config', type=str, default='configs/h36m/MotionAGFormer-base.yaml',
                       help='Config file path')
    parser.add_argument('--epochs', type=int, default=10, help='Number of epochs')
    parser.add_argument('--batch_size', type=int, default=64, help='Batch size')
    parser.add_argument('--device', type=str, default='auto', help='Device: auto, cpu, cuda')
    parser.add_argument('--model_type', type=str, default='mamba_gcn', 
                       choices=['baseline', 'mamba_gcn', 'full'],
                       help='Model configuration type')
    parser.add_argument('--save_dir', type=str, default='checkpoints/real_h36m',
                       help='Directory to save models')
    return parser.parse_args()


def get_device(device_str):
    if device_str == 'auto':
        return 'cuda' if torch.cuda.is_available() else 'cpu'
    return device_str


def create_model(args, model_type='baseline'):
    """Create model based on type"""
    
    if model_type == 'baseline':
        # Original MotionAGFormer
        model = MotionAGFormer(
            n_layers=args.n_layers,
            dim_in=args.dim_in,
            dim_feat=args.dim_feat,
            dim_out=args.dim_out,
            n_frames=args.n_frames,
            use_mamba_gcn=False
        )
    elif model_type == 'mamba_gcn':
        # MambaGCN enhanced
        model = MotionAGFormer(
            n_layers=args.n_layers,
            dim_in=args.dim_in,
            dim_feat=args.dim_feat,
            dim_out=args.dim_out,
            n_frames=args.n_frames,
            use_mamba_gcn=True,
            mamba_gcn_use_mamba=True,
            mamba_gcn_use_attention=False
        )
    elif model_type == 'full':
        # Full architecture with all components
        model = MotionAGFormer(
            n_layers=args.n_layers,
            dim_in=args.dim_in,
            dim_feat=args.dim_feat,
            dim_out=args.dim_out,
            n_frames=args.n_frames,
            use_mamba_gcn=True,
            mamba_gcn_use_mamba=True,
            mamba_gcn_use_attention=True
        )
    
    return model


def train_epoch(model, train_loader, optimizer, criterion, device):
    """Train for one epoch"""
    model.train()
    losses = AverageMeter()
    
    pbar = tqdm(train_loader, desc='Training')
    for batch_idx, (data_2d, data_3d) in enumerate(pbar):
        data_2d, data_3d = data_2d.to(device), data_3d.to(device)
        
        optimizer.zero_grad()
        pred_3d = model(data_2d)
        
        # Compute loss
        loss = criterion(pred_3d, data_3d)
        loss.backward()
        optimizer.step()
        
        losses.update(loss.item(), data_2d.size(0))
        pbar.set_postfix({'Loss': losses.avg})
        
    return losses.avg


def evaluate(model, test_loader, device, datareader):
    """Evaluate model performance"""
    model.eval()
    total_loss = 0
    total_samples = 0
    predictions = []
    targets = []
    
    with torch.no_grad():
        for data_2d, data_3d in tqdm(test_loader, desc='Evaluating'):
            data_2d, data_3d = data_2d.to(device), data_3d.to(device)
            
            pred_3d = model(data_2d)
            
            # Accumulate for MPJPE calculation
            predictions.append(pred_3d.cpu().numpy())
            targets.append(data_3d.cpu().numpy())
            
            total_samples += data_2d.size(0)
    
    # Calculate MPJPE
    predictions = np.concatenate(predictions, axis=0)
    targets = np.concatenate(targets, axis=0)
    
    # Denormalize predictions for proper MPJPE calculation
    predictions_denorm = datareader.denormalize(predictions, all_sequence=True)
    targets_denorm = datareader.denormalize(targets, all_sequence=True)
    
    # Calculate MPJPE in mm
    mpjpe = np.mean(np.sqrt(np.sum((predictions_denorm - targets_denorm) ** 2, axis=-1)))
    
    return mpjpe


def main():
    opts = parse_args()
    
    # Load config
    args = get_config(opts.config)
    
    # Override settings
    args.epochs = opts.epochs
    args.batch_size = opts.batch_size
    args.n_frames = 243
    
    # Set device
    device = get_device(opts.device)
    print(f"ğŸ”§ ä½¿ç”¨è®¾å¤‡: {device}")
    
    # Set random seed
    set_random_seed(42)
    
    # Create real data reader
    print("ğŸ“Š åŠ è½½çœŸå®Human3.6Mæ•°æ®...")
    datareader = DataReaderRealH36M(
        n_frames=args.n_frames,
        sample_stride=1,
        data_stride_train=81,
        data_stride_test=243,
        read_confidence=True,
        dt_root='data/motion3d/human36m/raw/motion3d'
    )
    
    # Get data
    train_data, test_data, train_labels, test_labels = datareader.get_sliced_data()
    print(f"âœ… çœŸå®æ•°æ®åŠ è½½å®Œæˆ:")
    print(f"   - è®­ç»ƒ: {train_data.shape} -> {train_labels.shape}")
    print(f"   - æµ‹è¯•: {test_data.shape} -> {test_labels.shape}")
    
    # Create datasets and loaders
    train_dataset = RealH36MDataset(train_data, train_labels)
    test_dataset = RealH36MDataset(test_data, test_labels)
    
    train_loader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True, 
                             num_workers=4, pin_memory=True)
    test_loader = DataLoader(test_dataset, batch_size=args.batch_size, shuffle=False,
                            num_workers=4, pin_memory=True)
    
    # Create model
    print(f"ğŸ§  åˆ›å»º {opts.model_type} æ¨¡å‹...")
    model = create_model(args, opts.model_type)
    model = model.to(device)
    
    # Setup training
    criterion = loss_mpjpe
    optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-5)
    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.9)
    
    # Create save directory
    os.makedirs(opts.save_dir, exist_ok=True)
    
    best_mpjpe = float('inf')
    
    print(f"ğŸš‚ å¼€å§‹è®­ç»ƒ ({opts.epochs} epochs)...")
    for epoch in range(opts.epochs):
        print(f"\\nEpoch {epoch+1}/{opts.epochs}")
        
        # Train
        train_loss = train_epoch(model, train_loader, optimizer, criterion, device)
        
        # Evaluate
        mpjpe = evaluate(model, test_loader, device, datareader)
        
        # Update learning rate
        scheduler.step()
        
        print(f"è®­ç»ƒæŸå¤±: {train_loss:.4f}, MPJPE: {mpjpe:.2f}mm")
        
        # Save best model
        if mpjpe < best_mpjpe:
            best_mpjpe = mpjpe
            torch.save({
                'epoch': epoch,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'mpjpe': mpjpe,
                'model_type': opts.model_type
            }, os.path.join(opts.save_dir, f'best_{opts.model_type}.pth'))
            print(f"ğŸ’¾ ä¿å­˜æœ€ä½³æ¨¡å‹ (MPJPE: {mpjpe:.2f}mm)")
    
    print(f"\\nğŸ‰ è®­ç»ƒå®Œæˆï¼æœ€ä½³MPJPE: {best_mpjpe:.2f}mm")
    print(f"ğŸ“ æ¨¡å‹ä¿å­˜åœ¨: {opts.save_dir}")


if __name__ == '__main__':
    main()
'''

    with open('scripts/train_real.py', 'w', encoding='utf-8') as f:
        f.write(train_real_content)

    print("âœ… çœŸå®æ•°æ®è®­ç»ƒè„šæœ¬å·²åˆ›å»º: scripts/train_real.py")


def update_baseline_validation():
    """æ›´æ–°baseline_validation.pyä»¥ä½¿ç”¨çœŸå®æ•°æ®"""
    print("\nğŸ”§ æ›´æ–°baseline_validation.py...")

    # Read existing file
    with open('baseline_validation.py', 'r', encoding='utf-8') as f:
        content = f.read()

    # Replace mock data reader import with real data reader
    content = content.replace(
        'from data.reader.mock_h36m import DataReaderMockH36M',
        'from data.reader.real_h36m import DataReaderRealH36M'
    )

    # Replace mock data reader instantiation
    content = content.replace(
        'DataReaderMockH36M(',
        'DataReaderRealH36M('
    )

    # Update data root path
    content = content.replace(
        "dt_root=args.data_root",
        "dt_root='data/motion3d/human36m/raw/motion3d'"
    )

    # Update comments
    content = content.replace(
        '# åˆ›å»º mock data reader',
        '# åˆ›å»ºçœŸå®Human3.6M data reader'
    )
    content = content.replace(
        'print("ğŸ“Š åŠ è½½mockæ•°æ®...")',
        'print("ğŸ“Š åŠ è½½çœŸå®Human3.6Mæ•°æ®...")'
    )

    # Write updated file
    with open('baseline_validation_real.py', 'w', encoding='utf-8') as f:
        f.write(content)

    print("âœ… æ›´æ–°å®Œæˆ: baseline_validation_real.py")


def create_comparison_script():
    """åˆ›å»ºmock vs realæ•°æ®æ€§èƒ½æ¯”è¾ƒè„šæœ¬"""
    print("\nğŸ“Š åˆ›å»ºæ€§èƒ½æ¯”è¾ƒè„šæœ¬...")

    comparison_content = '''#!/usr/bin/env python3
"""
Mock vs Real Data Performance Comparison
æ¯”è¾ƒæ¨¡æ‹Ÿæ•°æ®å’ŒçœŸå®Human3.6Mæ•°æ®çš„æ¨¡å‹æ€§èƒ½
"""

import torch
import numpy as np
from datetime import datetime
import os

from data.reader.mock_h36m import DataReaderMockH36M
from data.reader.real_h36m import DataReaderRealH36M
from model.MotionAGFormer import MotionAGFormer
from loss.pose3d import loss_mpjpe
from utils.tools import set_random_seed


def quick_test(datareader, data_type, model_type='baseline'):
    """Quick performance test"""
    print(f"\\nğŸ§ª æµ‹è¯• {data_type} æ•°æ® ({model_type})...")
    
    # Get small sample
    train_data, test_data, train_labels, test_labels = datareader.get_sliced_data()
    
    # Take small sample for quick test
    sample_size = min(100, len(test_data))
    test_data_sample = test_data[:sample_size]
    test_labels_sample = test_labels[:sample_size]
    
    print(f"   æµ‹è¯•æ ·æœ¬: {test_data_sample.shape} -> {test_labels_sample.shape}")
    
    # Create model
    if model_type == 'baseline':
        model = MotionAGFormer(
            n_layers=4, dim_in=2, dim_feat=64, dim_out=3, n_frames=243,
            use_mamba_gcn=False
        )
    else:  # mamba_gcn
        model = MotionAGFormer(
            n_layers=4, dim_in=2, dim_feat=64, dim_out=3, n_frames=243,
            use_mamba_gcn=True, mamba_gcn_use_mamba=True, mamba_gcn_use_attention=False
        )
    
    model.eval()
    
    # Convert to tensors
    input_tensor = torch.FloatTensor(test_data_sample)
    target_tensor = torch.FloatTensor(test_labels_sample)
    
    # Forward pass
    with torch.no_grad():
        pred_tensor = model(input_tensor)
    
    # Calculate loss
    loss_value = loss_mpjpe(pred_tensor, target_tensor).item()
    
    # Calculate MPJPE in original scale (approximate)
    pred_np = pred_tensor.numpy()
    target_np = target_tensor.numpy()
    mpjpe = np.mean(np.sqrt(np.sum((pred_np - target_np) ** 2, axis=-1))) * 1000  # Convert to mm
    
    print(f"   æŸå¤±: {loss_value:.4f}")
    print(f"   MPJPE: {mpjpe:.2f}mm")
    
    return {
        'data_type': data_type,
        'model_type': model_type,
        'loss': loss_value,
        'mpjpe': mpjpe,
        'sample_size': sample_size
    }


def main():
    print("ğŸ“‹ Mock vs Real Data Performance Comparison")
    print("=" * 60)
    
    set_random_seed(42)
    results = []
    
    # Test with Mock Data
    try:
        mock_reader = DataReaderMockH36M(
            n_frames=243, sample_stride=1, data_stride_train=81, data_stride_test=243,
            read_confidence=True, dt_root='data/motion3d'
        )
        
        # Test baseline and mamba_gcn with mock data
        results.append(quick_test(mock_reader, 'Mock', 'baseline'))
        results.append(quick_test(mock_reader, 'Mock', 'mamba_gcn'))
        
    except Exception as e:
        print(f"âŒ Mockæ•°æ®æµ‹è¯•å¤±è´¥: {e}")
    
    # Test with Real Data
    try:
        real_reader = DataReaderRealH36M(
            n_frames=243, sample_stride=1, data_stride_train=81, data_stride_test=243,
            read_confidence=True, dt_root='data/motion3d/human36m/raw/motion3d'
        )
        
        # Test baseline and mamba_gcn with real data
        results.append(quick_test(real_reader, 'Real', 'baseline'))
        results.append(quick_test(real_reader, 'Real', 'mamba_gcn'))
        
    except Exception as e:
        print(f"âŒ çœŸå®æ•°æ®æµ‹è¯•å¤±è´¥: {e}")
    
    # Summary
    print("\\n" + "=" * 60)
    print("ğŸ“Š æ€§èƒ½æ¯”è¾ƒæ€»ç»“")
    print("=" * 60)
    
    for result in results:
        print(f"{result['data_type']} + {result['model_type']:<10}: "
              f"MPJPE = {result['mpjpe']:.2f}mm, Loss = {result['loss']:.4f}")
    
    # Find best configuration
    if results:
        best_result = min(results, key=lambda x: x['mpjpe'])
        print(f"\\nğŸ† æœ€ä½³é…ç½®: {best_result['data_type']} + {best_result['model_type']} "
              f"(MPJPE: {best_result['mpjpe']:.2f}mm)")
    
    # Save results
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    results_file = f"data_comparison_results_{timestamp}.json"
    
    import json
    with open(results_file, 'w') as f:
        json.dump(results, f, indent=2)
    
    print(f"ğŸ“ è¯¦ç»†ç»“æœä¿å­˜åˆ°: {results_file}")


if __name__ == '__main__':
    main()
'''

    with open('compare_data_performance.py', 'w', encoding='utf-8') as f:
        f.write(comparison_content)

    print("âœ… æ€§èƒ½æ¯”è¾ƒè„šæœ¬å·²åˆ›å»º: compare_data_performance.py")


def update_demo_script():
    """æ›´æ–°demo.pyä»¥æ”¯æŒçœŸå®æ•°æ®"""
    print("\nğŸ­ æ›´æ–°demo.py...")

    # Read existing demo.py
    with open('demo.py', 'r', encoding='utf-8') as f:
        content = f.read()

    # Add real data import
    content = content.replace(
        'from data.reader.mock_h36m import DataReaderMockH36M',
        '''from data.reader.mock_h36m import DataReaderMockH36M
from data.reader.real_h36m import DataReaderRealH36M'''
    )

    # Add real data option to demo
    real_data_method = '''
    def load_real_data(self, subset='test', max_samples=1000):
        """åŠ è½½çœŸå®Human3.6Mæ•°æ®"""
        print(f"\\nğŸ“Š åŠ è½½çœŸå®Human3.6Mæ•°æ® ({subset})...")
        
        try:
            datareader = DataReaderRealH36M(
                n_frames=243, sample_stride=1, data_stride_train=81, data_stride_test=243,
                read_confidence=True, dt_root='data/motion3d/human36m/raw/motion3d'
            )
            
            train_data, test_data, train_labels, test_labels = datareader.get_sliced_data()
            
            if subset == 'train':
                data_2d, data_3d = train_data, train_labels
            else:
                data_2d, data_3d = test_data, test_labels
            
            # Limit sample size for demo
            if len(data_2d) > max_samples:
                indices = np.random.choice(len(data_2d), max_samples, replace=False)
                data_2d = data_2d[indices]
                data_3d = data_3d[indices]
            
            data_2d = torch.FloatTensor(data_2d).to(self.device)
            data_3d = torch.FloatTensor(data_3d).to(self.device)
            
            print(f"   âœ… çœŸå®æ•°æ®åŠ è½½å®Œæˆ: {data_2d.shape} -> {data_3d.shape}")
            return data_2d, data_3d, datareader
            
        except Exception as e:
            print(f"   âŒ çœŸå®æ•°æ®åŠ è½½å¤±è´¥: {e}")
            print("   ğŸ”„ fallbackåˆ°mockæ•°æ®...")
            return None, None, None'''

    # Insert the method after create_demo_data method
    insertion_point = content.find(
        'def compare_models(self, data_2d, data_3d):')
    if insertion_point != -1:
        content = content[:insertion_point] + real_data_method + \
            '\n\n    ' + content[insertion_point:]

    # Update demo execution modes
    content = content.replace(
        "modes = ['quick', 'full', 'config']",
        "modes = ['quick', 'full', 'config', 'real']"
    )

    # Add real data execution mode
    real_mode_code = '''
        elif mode == 'real':
            print("\\nğŸ¯ çœŸå®æ•°æ®æ¼”ç¤ºæ¨¡å¼")
            # Try to load real data
            real_2d, real_3d, real_reader = self.load_real_data(subset='test', max_samples=500)
            
            if real_2d is not None:
                print("\\nğŸ“Š ä½¿ç”¨çœŸå®Human3.6Mæ•°æ®è¿›è¡Œæ¼”ç¤º...")
                data_2d, data_3d = real_2d, real_3d
                
                # Model comparison with real data
                results = self.compare_models(data_2d, data_3d)
                self.results[f'real_data'] = results
                
                # Generate report
                self.generate_report()
                
                print("\\nğŸ‰ çœŸå®æ•°æ®æ¼”ç¤ºå®Œæˆï¼")
            else:
                print("\\nâš ï¸  çœŸå®æ•°æ®ä¸å¯ç”¨ï¼Œä½¿ç”¨mockæ•°æ®ç»§ç»­æ¼”ç¤º")
                mode = 'quick'  # Fallback to quick mode'''

    # Insert real mode handling
    config_mode_end = content.find('print("\\nğŸ‰ é…ç½®æ¼”ç¤ºå®Œæˆï¼")')
    if config_mode_end != -1:
        next_elif = content.find('else:', config_mode_end)
        if next_elif != -1:
            content = content[:next_elif] + real_mode_code + \
                '\n        ' + content[next_elif:]

    # Write updated demo
    with open('demo_real.py', 'w', encoding='utf-8') as f:
        f.write(content)

    print("âœ… æ›´æ–°å®Œæˆ: demo_real.py (æ”¯æŒçœŸå®æ•°æ®)")


def main():
    parser = argparse.ArgumentParser(description='æ•°æ®è¿ç§»: Mock â†’ Real Human3.6M')
    parser.add_argument('--check-only', action='store_true', help='ä»…æ£€æŸ¥æ•°æ®å¯ç”¨æ€§')
    parser.add_argument('--backup', action='store_true', help='å¤‡ä»½ç°æœ‰mockæ–‡ä»¶')
    parser.add_argument('--force', action='store_true', help='å¼ºåˆ¶æ‰§è¡Œè¿ç§»')
    args = parser.parse_args()

    print("ğŸ”„ Human3.6Mæ•°æ®è¿ç§»å·¥å…·")
    print("=" * 50)
    print("ç›®æ ‡: å°†é¡¹ç›®ä»æ¨¡æ‹Ÿæ•°æ®è½¬æ¢ä¸ºçœŸå®Human3.6Mæ•°æ®")
    print("=" * 50)

    # Step 1: Check data availability
    data_available = check_real_data_availability()

    if not data_available:
        print("\\nâŒ çœŸå®æ•°æ®ä¸å®Œæ•´ï¼Œæ— æ³•è¿›è¡Œè¿ç§»")
        print("ğŸ’¡ è¯·ç¡®ä¿ä»¥ä¸‹æ•°æ®æ–‡ä»¶å­˜åœ¨:")
        print("  - data/motion3d/human36m/raw/motion3d/h36m_sh_conf_cam_source_final.pkl")
        print("  - data/motion3d/human36m/raw/motion3d/H36M-243/train/")
        print("  - data/motion3d/human36m/raw/motion3d/H36M-243/test/")
        return False

    if args.check_only:
        print("\\nâœ… æ•°æ®æ£€æŸ¥å®Œæˆï¼Œæ‰€æœ‰çœŸå®æ•°æ®éƒ½å¯ç”¨")
        return True

    # Step 2: Backup mock files
    if args.backup:
        backup_mock_files()

    # Step 3: Create new files for real data
    create_real_training_script()
    update_baseline_validation()
    create_comparison_script()
    update_demo_script()

    # Step 4: Test real data loading
    print("\\nğŸ§ª æµ‹è¯•çœŸå®æ•°æ®åŠ è½½...")
    try:
        from data.reader.real_h36m import DataReaderRealH36M

        reader = DataReaderRealH36M(
            n_frames=243, sample_stride=1, data_stride_train=81, data_stride_test=243,
            read_confidence=True, dt_root='data/motion3d/human36m/raw/motion3d'
        )

        train_data, test_data, train_labels, test_labels = reader.get_sliced_data()
        print(f"  âœ… è®­ç»ƒæ•°æ®: {train_data.shape} -> {train_labels.shape}")
        print(f"  âœ… æµ‹è¯•æ•°æ®: {test_data.shape} -> {test_labels.shape}")

    except Exception as e:
        print(f"  âŒ æ•°æ®åŠ è½½æµ‹è¯•å¤±è´¥: {e}")
        return False

    # Step 5: Summary
    print("\\n" + "=" * 50)
    print("âœ… æ•°æ®è¿ç§»å®Œæˆæ€»ç»“")
    print("=" * 50)
    print("ğŸ†• æ–°åˆ›å»ºçš„æ–‡ä»¶:")
    print("  - data/reader/real_h36m.py          # çœŸå®æ•°æ®è¯»å–å™¨")
    print("  - scripts/train_real.py             # çœŸå®æ•°æ®è®­ç»ƒè„šæœ¬")
    print("  - baseline_validation_real.py       # çœŸå®æ•°æ®åŸºçº¿éªŒè¯")
    print("  - compare_data_performance.py       # Mock vs Real æ€§èƒ½æ¯”è¾ƒ")
    print("  - demo_real.py                      # æ”¯æŒçœŸå®æ•°æ®çš„æ¼”ç¤º")

    print("\\nğŸ”§ ä½¿ç”¨æ–¹æ³•:")
    print("  # æ€§èƒ½æ¯”è¾ƒ")
    print("  python compare_data_performance.py")
    print()
    print("  # çœŸå®æ•°æ®è®­ç»ƒ")
    print("  python scripts/train_real.py --model_type mamba_gcn --epochs 5")
    print()
    print("  # çœŸå®æ•°æ®åŸºçº¿éªŒè¯")
    print("  python baseline_validation_real.py")
    print()
    print("  # çœŸå®æ•°æ®æ¼”ç¤º")
    print("  python demo_real.py real")

    print("\\nğŸ¯ ä¸‹ä¸€æ­¥å»ºè®®:")
    print("  1. è¿è¡Œæ€§èƒ½æ¯”è¾ƒäº†è§£çœŸå® vs æ¨¡æ‹Ÿæ•°æ®çš„å·®å¼‚")
    print("  2. ä½¿ç”¨çœŸå®æ•°æ®é‡æ–°è®­ç»ƒå’ŒéªŒè¯æ¨¡å‹")
    print("  3. æ›´æ–°æœ€ç»ˆäº¤ä»˜æ–‡æ¡£ä¸­çš„æ€§èƒ½æŒ‡æ ‡")

    print("\\nğŸ‰ è¿ç§»å®Œæˆï¼é¡¹ç›®ç°åœ¨å¯ä»¥ä½¿ç”¨çœŸå®Human3.6Mæ•°æ®äº†")
    return True


if __name__ == '__main__':
    success = main()
    sys.exit(0 if success else 1)
